{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZNOj7ujEYV1fbp0JTTZ7gEbtpbi95aNx",
      "authorship_tag": "ABX9TyPC9ITfvP1Y/QGx1GjGFa4v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosks/carlosks/blob/main/ChatOpenAiNoelAdocao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt_iqhfiG3Fz",
        "outputId": "479a17c3-2ed7-46ed-d31b-e34c540178de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo no Google Drive\n",
        "file_path = '/content/index.js'\n",
        "\n",
        "# Ler o conteúdo do arquivo\n",
        "def read_file_content(file_path):\n",
        "    # Trying to read the file with 'utf-8' encoding.\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read()\n",
        "    # If 'utf-8' fails, try 'latin-1' encoding.\n",
        "    except UnicodeDecodeError:\n",
        "        with open(file_path, 'r', encoding='latin-1') as f:\n",
        "            return f.read()\n",
        "\n",
        "# Lendo o conteúdo do arquivo\n",
        "content = read_file_content(file_path)\n",
        "print(\"Conteúdo do arquivo:\\n\", content[:500])  # Exibindo os primeiros 500 caracteres do arquivo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pxVUZBZFlGg",
        "outputId": "205e7d90-3523-4541-8c9b-7029ab965f4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteúdo do arquivo:\n",
            " totalCartas = 0;\n",
            "filtrosChecked = '';\n",
            "filtros = [];\n",
            "filtross = {};\n",
            "filters = {};\n",
            "$(\"#botaoAdocao\").hide();\n",
            "pontoSelecionado = \"\";\n",
            "\n",
            "const limiteCartasAdotadas = 30;\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "$(document).on('click', '.btn-m-confirma-adocao', function () {\n",
            "Ê Ê location.href = `../adocao/ambientePadrinho/index.php`;\n",
            "});\n",
            "\n",
            "$(document).on('click', '.btn-m-confirma-cidade', function () {\n",
            "Ê Ê location.href = `../adocao/index.php`;\n",
            "});\n",
            "\n",
            "window.document.addEventListener('DOMContentLoaded', function() {\n",
            "Ê Ê console.log(localStor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiCl2YaiUC5P",
        "outputId": "02c90a57-a53d-4640-9d85-e5b8bb67dd0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.52.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.52.1-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.1 openai-1.52.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "\n",
        "# Configurar a API da OpenAI\n",
        "\n",
        "openai.api_key = 'sua-chave-da-api'\n",
        "\n",
        "\n",
        "\n",
        "def ask_openai(question, code_context):\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "\n",
        "        engine=\"gpt-4\",  # Pode ser gpt-3.5-turbo ou outro modelo\n",
        "\n",
        "        prompt=f\"Este é o conteúdo do arquivo:\\n{code_context}\\n\\nResponda à pergunta: {question}\",\n",
        "\n",
        "        max_tokens=500,\n",
        "\n",
        "        temperature=0.7\n",
        "\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "\n",
        "\n",
        "# Exemplo de uso: Perguntar sobre o conteúdo do arquivo\n",
        "\n",
        "question = \"Analise o conteúdo do arquivo index.js\"\n",
        "\n",
        "response = ask_openai(question, content[:3000])  # Limite o número de caracteres para não ultrapassar o limite de tokens\n",
        "\n",
        "print(\"Resposta da OpenAI:\", response)\n",
        "\n"
      ],
      "metadata": {
        "id": "GrOhPEathTu-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}